#!/usr/bin/env python3
"""
README generation module for the repository tracker.

Handles generation of English and Korean README files with data collection capability.
"""

import json
import os
import re
from datetime import datetime
from typing import Dict, List, Optional

import requests


def generate_readme_english(repo_data: List[Dict], output_file: str = "README.md") -> None:
    """Generate English README.md file from repository data."""
    # Sort by stars (descending)
    repo_data.sort(key=lambda x: x["stars"], reverse=True)

    timestamp = datetime.now().strftime("%Y-%m-%dT%H:%M:%S")

    header = """# Python Repository Trends Tracker

A tool that automatically tracks and ranks popular Python projects on GitHub by star count, fork count, and issue count.

## ðŸš€ Demo

Visit the [demo page](https://0x10.kr) to see real-time rankings and charts.

## ðŸ“Š Project Overview

This tool monitors various categories of Python projects and provides the following features:

- **Automatic Data Collection**: Uses GitHub GraphQL API to collect accurate star, fork, issue, and PR counts
- **History Tracking**: Tracks daily changes for trend analysis over time
- **Real-time Updates**: Automated daily updates via GitHub Actions
- **Multiple Categories**: Includes web frameworks, machine learning, data science, Python implementations, and more

## ðŸŽ¯ Tracked Categories

- **Web Frameworks**: Django, Flask, FastAPI, Tornado, etc.
- **Machine Learning/AI**: TensorFlow, PyTorch, scikit-learn, Keras, etc.
- **Data Science**: Pandas, NumPy, SciPy, Matplotlib, etc.
- **Async Programming**: asyncio, trio, anyio, etc.
- **Python Implementations**: CPython, PyPy, Jython, MicroPython, etc.

## ðŸ› ï¸ Scripts Documentation

### Core Scripts

- **`fetcher.py`** - Main data collection and README generation script
  - Fetches repository data from GitHub API
  - Updates local JSON data files with daily changes
  - Generates both English and Korean README files
  - Uses GraphQL API for accurate issue/PR counts

- **`readme_generator.py`** - Standalone README generation utility
  - Loads data from existing local JSON files
  - Optionally updates with current GitHub data
  - Generates README files without full data collection
  - Lightweight alternative for quick README updates

- **`repo_data_initializer.py`** - Single repository data collector
  - Initializes data for a single GitHub repository
  - Fetches historical stargazer data using GraphQL
  - Creates initial JSON data file in repo_data/ directory

- **`batch_repo_initializer.py`** - Batch repository processor
  - Processes multiple repositories in parallel
  - Configurable worker threads (default: 3 CPUs)
  - Ideal for initial data collection of all repositories

- **`generate_history_from_repo_data.py`** - History aggregator
  - Converts daily repository data into cumulative totals
  - Generates repository_histories.json for trend analysis
  - Processes all repo_data/*.json files

### Usage Examples

```bash
# Full data collection and README generation
uv run python/fetcher.py

# Quick README update only
uv run python/readme_generator.py

# Initialize single repository
uv run python/repo_data_initializer.py https://github.com/owner/repo

# Process all repositories in batch
uv run python/batch_repo_initializer.py --workers 8

# Generate history aggregation
uv run python/generate_history_from_repo_data.py
```

| Project Name | Stars | Forks | Total Issues | Total PRs | Open Issues | Last Commit |
| ------------ | ----- | ----- | ------------ | --------- | ----------- | ----------- |
"""

    with open(output_file, "w", encoding="utf-8") as f:
        f.write(header)

        for project in repo_data:
            # Format last commit date
            if project["last_commit"]:
                try:
                    commit_date = datetime.fromisoformat(project["last_commit"].replace("Z", "+00:00")).strftime(
                        "%Y-%m-%d %H:%M:%S"
                    )
                except (ValueError, TypeError):
                    commit_date = "N/A"
            else:
                commit_date = "N/A"

            f.write(
                f"| [{project['name']}]({project['html_url']}) | "
                f"{project['stars']} | "
                f"{project['forks']} | "
                f"{project.get('total_issues', 'N/A')} | "
                f"{project.get('total_pull_requests', 'N/A')} | "
                f"{project['open_issues']} | "
                f"{commit_date} |\n"
            )

        # Add footer
        f.write(f"\n*Last Automatic Update: {timestamp}*\n")
        f.write("\n*Inspired by https://github.com/mingrammer/python-web-framework-stars*\n")

    print(f"Generated English {output_file} with {len(repo_data)} projects")


def generate_readme_korean(repo_data: List[Dict], output_file: str = "README-KR.md") -> None:
    """Generate Korean README-KR.md file from repository data."""
    # Sort by stars (descending)
    repo_data.sort(key=lambda x: x["stars"], reverse=True)

    timestamp = datetime.now().strftime("%Y-%m-%dT%H:%M:%S")

    header = """# íŒŒì´ì¬ ë ˆí¬ì§€í† ë¦¬ íŠ¸ëžœë“œ íŠ¸ëž˜ì»¤

GitHubì—ì„œ ì¸ê¸° ìžˆëŠ” íŒŒì´ì¬ í”„ë¡œì íŠ¸ë“¤ì˜ ìŠ¤íƒ€ ìˆ˜, í¬í¬ ìˆ˜, ì´ìŠˆ ìˆ˜ë¥¼ ìžë™ìœ¼ë¡œ ì¶”ì í•˜ê³  ìˆœìœ„ë¥¼ ë§¤ê¸°ëŠ” ë„êµ¬ìž…ë‹ˆë‹¤.

## ðŸš€ ë°ëª¨

ì‹¤ì‹œê°„ ìˆœìœ„ ë° ì°¨íŠ¸ë¥¼ í™•ì¸í•˜ë ¤ë©´ [ë°ëª¨ íŽ˜ì´ì§€](https://0x10.kr)ë¥¼ ë°©ë¬¸í•˜ì„¸ìš”.

## ðŸ“Š í”„ë¡œì íŠ¸ ì†Œê°œ

ì´ ë„êµ¬ëŠ” ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ì˜ íŒŒì´ì¬ í”„ë¡œì íŠ¸ë“¤ì„ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:

- **ìžë™ ë°ì´í„° ìˆ˜ì§‘**: GitHub GraphQL APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ìŠ¤íƒ€, í¬í¬, ì´ìŠˆ, PR ìˆ˜ë¥¼ ìˆ˜ì§‘
- **ížˆìŠ¤í† ë¦¬ ì¶”ì **: ì¼ë³„ ë³€í™”ëŸ‰ì„ ì¶”ì í•˜ì—¬ ì‹œê°„ì— ë”°ë¥¸ íŠ¸ë Œë“œ ë¶„ì„ ê°€ëŠ¥
- **ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸**: GitHub Actionsë¥¼ í†µí•œ ë§¤ì¼ ìžë™ ì—…ë°ì´íŠ¸
- **ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬**: ì›¹ í”„ë ˆìž„ì›Œí¬, ë¨¸ì‹ ëŸ¬ë‹, ë°ì´í„° ê³¼í•™, Python êµ¬í˜„ì²´ ë“± í¬í•¨

## ðŸŽ¯ ì¶”ì  ì¹´í…Œê³ ë¦¬

- **ì›¹ í”„ë ˆìž„ì›Œí¬**: Django, Flask, FastAPI, Tornado ë“±
- **ë¨¸ì‹ ëŸ¬ë‹/AI**: TensorFlow, PyTorch, scikit-learn, Keras ë“±  
- **ë°ì´í„° ê³¼í•™**: Pandas, NumPy, SciPy, Matplotlib ë“±
- **ë¹„ë™ê¸° í”„ë¡œê·¸ëž˜ë°**: asyncio, trio, anyio ë“±
- **Python êµ¬í˜„ì²´**: CPython, PyPy, Jython, MicroPython ë“±

## ðŸ› ï¸ ìŠ¤í¬ë¦½íŠ¸ ë¬¸ì„œ

### í•µì‹¬ ìŠ¤í¬ë¦½íŠ¸

- **`fetcher.py`** - ë©”ì¸ ë°ì´í„° ìˆ˜ì§‘ ë° README ìƒì„± ìŠ¤í¬ë¦½íŠ¸
  - GitHub APIì—ì„œ ì €ìž¥ì†Œ ë°ì´í„° ìˆ˜ì§‘
  - ë¡œì»¬ JSON ë°ì´í„° íŒŒì¼ì„ ì¼ë³„ ë³€ê²½ì‚¬í•­ìœ¼ë¡œ ì—…ë°ì´íŠ¸
  - ì˜ì–´ ë° í•œê¸€ README íŒŒì¼ ìƒì„±
  - GraphQL APIë¥¼ ì‚¬ìš©í•œ ì •í™•í•œ ì´ìŠˆ/PR ìˆ˜ ì¡°íšŒ

- **`readme_generator.py`** - ë…ë¦½í˜• README ìƒì„± ìœ í‹¸ë¦¬í‹°
  - ê¸°ì¡´ ë¡œì»¬ JSON íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ
  - ì„ íƒì ìœ¼ë¡œ í˜„ìž¬ GitHub ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸
  - ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì—†ì´ README íŒŒì¼ ìƒì„±
  - ë¹ ë¥¸ README ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ê²½ëŸ‰í™” ëŒ€ì•ˆ

- **`repo_data_initializer.py`** - ë‹¨ì¼ ì €ìž¥ì†Œ ë°ì´í„° ìˆ˜ì§‘ê¸°
  - ë‹¨ì¼ GitHub ì €ìž¥ì†Œ ë°ì´í„° ì´ˆê¸°í™”
  - GraphQLì„ ì‚¬ìš©í•œ ê³¼ê±° ìŠ¤íƒ€ ë°ì´í„° ìˆ˜ì§‘
  - repo_data/ ë””ë ‰í† ë¦¬ì— ì´ˆê¸° JSON ë°ì´í„° íŒŒì¼ ìƒì„±

- **`batch_repo_initializer.py`** - ë°°ì¹˜ ì €ìž¥ì†Œ ì²˜ë¦¬ê¸°
  - ì—¬ëŸ¬ ì €ìž¥ì†Œë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬
  - ì„¤ì • ê°€ëŠ¥í•œ ì›Œì»¤ ìŠ¤ë ˆë“œ (ê¸°ë³¸ê°’: 3 CPU)
  - ëª¨ë“  ì €ìž¥ì†Œì˜ ì´ˆê¸° ë°ì´í„° ìˆ˜ì§‘ì— ì´ìƒì 

- **`generate_history_from_repo_data.py`** - ížˆìŠ¤í† ë¦¬ ì§‘ê³„ê¸°
  - ì¼ë³„ ì €ìž¥ì†Œ ë°ì´í„°ë¥¼ ëˆ„ì  í•©ê³„ë¡œ ë³€í™˜
  - íŠ¸ë Œë“œ ë¶„ì„ì„ ìœ„í•œ repository_histories.json ìƒì„±
  - ëª¨ë“  repo_data/*.json íŒŒì¼ ì²˜ë¦¬

### ì‚¬ìš© ì˜ˆì‹œ

```bash
# ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ë° README ìƒì„±
uv run python/fetcher.py

# READMEë§Œ ë¹ ë¥´ê²Œ ì—…ë°ì´íŠ¸
uv run python/readme_generator.py

# ë‹¨ì¼ ì €ìž¥ì†Œ ì´ˆê¸°í™”
uv run python/repo_data_initializer.py https://github.com/owner/repo

# ëª¨ë“  ì €ìž¥ì†Œ ë°°ì¹˜ ì²˜ë¦¬
uv run python/batch_repo_initializer.py --workers 8

# ížˆìŠ¤í† ë¦¬ ì§‘ê³„ ìƒì„±
uv run python/generate_history_from_repo_data.py
```

| í”„ë¡œì íŠ¸ ì´ë¦„ | ìŠ¤íƒ€ ìˆ˜ | í¬í¬ ìˆ˜ | ì „ì²´ ì´ìŠˆ | ì „ì²´ PR | ì˜¤í”ˆ ì´ìŠˆ | ìµœê·¼ ì»¤ë°‹ |
| ------------ | ----- | ----- | ------------ | --------- | ----------- | ----------- |
"""

    with open(output_file, "w", encoding="utf-8") as f:
        f.write(header)

        for project in repo_data:
            # Format last commit date
            if project["last_commit"]:
                try:
                    commit_date = datetime.fromisoformat(project["last_commit"].replace("Z", "+00:00")).strftime(
                        "%Y-%m-%d %H:%M:%S"
                    )
                except (ValueError, TypeError):
                    commit_date = "N/A"
            else:
                commit_date = "N/A"

            f.write(
                f"| [{project['name']}]({project['html_url']}) | "
                f"{project['stars']} | "
                f"{project['forks']} | "
                f"{project.get('total_issues', 'N/A')} | "
                f"{project.get('total_pull_requests', 'N/A')} | "
                f"{project['open_issues']} | "
                f"{commit_date} |\n"
            )

        # Add footer
        f.write(f"\n*Last Automatic Update: {timestamp}*\n")
        f.write("\n*Inspired by https://github.com/mingrammer/python-web-framework-stars*\n")

    print(f"Generated Korean {output_file} with {len(repo_data)} projects")


def update_readme_timestamp(output_file: str = "README.md") -> None:
    """Update only the Last Automatic Update timestamp in README.md."""
    if not os.path.exists(output_file):
        print(f"Warning: {output_file} not found. Cannot update timestamp.")
        return

    try:
        # Read existing README content
        with open(output_file, "r", encoding="utf-8") as f:
            content = f.read()

        # Update timestamp line
        timestamp = datetime.now().strftime("%Y-%m-%dT%H:%M:%S")

        # Replace the Last Automatic Update line
        pattern = r"\*Last Automatic Update: [^*]*\*"
        replacement = f"*Last Automatic Update: {timestamp}*"

        if re.search(pattern, content):
            updated_content = re.sub(pattern, replacement, content)
        else:
            # If pattern not found, append timestamp at the end
            updated_content = content.rstrip() + f"\n\n*Last Automatic Update: {timestamp}*\n"

        # Write back to file
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(updated_content)

        print(f"Updated timestamp in {output_file}")

    except Exception as e:
        print(f"Failed to update timestamp in {output_file}: {e}")


def load_existing_repo_data() -> List[Dict]:
    """Load repository data from existing repo_data files."""
    repo_data_dir = "repo_data"
    
    if not os.path.exists(repo_data_dir):
        print(f"Warning: Directory '{repo_data_dir}' not found")
        return []
    
    all_repo_data = []
    
    # Get all JSON files in repo_data directory
    for filename in os.listdir(repo_data_dir):
        if not filename.endswith(".json"):
            continue
            
        repo_file_path = os.path.join(repo_data_dir, filename)
        
        try:
            with open(repo_file_path, "r", encoding="utf-8") as f:
                repo_data = json.load(f)
            
            # Extract owner and repo name from filename
            name_part = filename.replace(".json", "")
            if "_" in name_part:
                owner, repo_name = name_part.split("_", 1)
                
                # Create repository data structure
                project_data = {
                    "name": repo_name,
                    "html_url": f"https://github.com/{owner}/{repo_name}",
                    "stars": repo_data.get("total_stars", 0),
                    "forks": repo_data.get("total_forks", 0),
                    "open_issues": 0,  # Will be updated if we have current data
                    "total_issues": repo_data.get("total_issues", 0),
                    "total_pull_requests": repo_data.get("total_pull_requests", 0),
                    "last_commit": repo_data.get("last_commit", ""),
                    "fetched_at": repo_data.get("fetched_at", "")
                }
                
                all_repo_data.append(project_data)
                
        except Exception as e:
            print(f"Warning: Failed to load data from {filename}: {e}")
            continue
    
    print(f"Loaded data for {len(all_repo_data)} repositories from local files")
    return all_repo_data


def get_github_token() -> Optional[str]:
    """Get GitHub token from environment or file."""
    token = os.environ.get("GITHUB_TOKEN")
    if token:
        return token
    try:
        with open("access_token.txt", "r") as f:
            return f.read().strip()
    except FileNotFoundError:
        return None


def get_current_repo_data(owner: str, repo: str, token: Optional[str] = None) -> Optional[Dict]:
    """Get current repository data from GitHub API for README generation."""
    headers = {"User-Agent": "Python-Framework-Tracker"}
    if token:
        headers["Authorization"] = f"Bearer {token}"

    try:
        # Get basic repository data
        repo_url = f"https://api.github.com/repos/{owner}/{repo}"
        response = requests.get(repo_url, headers=headers)
        response.raise_for_status()
        repo_data = response.json()

        return {
            "name": repo,
            "html_url": repo_data.get("html_url", ""),
            "stars": repo_data.get("stargazers_count", 0),
            "forks": repo_data.get("forks_count", 0),
            "open_issues": repo_data.get("open_issues_count", 0),
            "total_issues": 0,  # Will use existing data
            "total_pull_requests": 0,  # Will use existing data
            "last_commit": repo_data.get("pushed_at", ""),
            "fetched_at": datetime.now().isoformat(),
        }

    except requests.exceptions.RequestException as e:
        print(f"Warning: Failed to fetch current data for {owner}/{repo}: {e}")
        return None


def update_repo_data_with_current() -> List[Dict]:
    """Update repository data with current GitHub data where possible."""
    existing_data = load_existing_repo_data()
    token = get_github_token()
    
    if not token:
        print("Warning: No GitHub token found. Using existing data only.")
        return existing_data
    
    updated_data = []
    
    for repo in existing_data:
        # Extract owner and repo name from html_url
        try:
            url_path = repo["html_url"].replace("https://github.com/", "")
            owner, repo_name = url_path.split("/")
            
            # Try to get current data
            current = get_current_repo_data(owner, repo_name, token)
            
            if current:
                # Update with current data while keeping historical totals
                repo["stars"] = current["stars"]
                repo["forks"] = current["forks"]
                repo["open_issues"] = current["open_issues"]
                repo["last_commit"] = current["last_commit"]
                repo["fetched_at"] = current["fetched_at"]
                
            updated_data.append(repo)
            
        except Exception as e:
            print(f"Warning: Failed to update data for {repo.get('name', 'unknown')}: {e}")
            updated_data.append(repo)  # Keep existing data
            continue
    
    return updated_data


def main():
    """Main execution function for standalone README generation."""
    print("Starting README generation...")
    
    try:
        # Load and update repository data
        print("Loading repository data...")
        repo_data = update_repo_data_with_current()
        
        if not repo_data:
            print("No repository data found. Exiting.")
            return
        
        # Generate both README files
        print("Generating README files...")
        generate_readme_english(repo_data)
        generate_readme_korean(repo_data)
        
        print("README generation completed successfully!")
        
    except Exception as e:
        print(f"Error: {e}")
        exit(1)


if __name__ == "__main__":
    main()
